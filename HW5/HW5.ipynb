{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete the `NotImplemented` parts of the code cells and write your answers in the markdown cells designated for your response to any questions asked. The tag `# AUTOGRADED` (all caps, with a space after `#`) should be at the beginning of each autograded code cell, so make sure that you do not change that. You are also not allowed to import any new package other than the ones already imported. Doing so will prevent the autograder from grading your code.\n",
    "\n",
    "For the code submission, run the last cell in the notebook to create the submission zip file. If you are working in Colab, make sure to download and then upload a copy of the completed notebook itself to its working directory to be included in the zip file. Finally, submit the zip file to Gradescope.\n",
    "\n",
    "After you finish the assignment and fill in your code and response where needed (all cells should have been run), save the notebook as a PDF using the `jupyter nbconvert --to pdf HW5.ipynb` command (via a notebook code cell or the command line directly) and submit the PDF to Gradescope under the PDF submission item. If you cannot get this to work locally, you can upload the notebook to Google Colab and create the PDF there. You can find the notebook containing the instruction for this on Canvas.\n",
    "\n",
    "If you are running the notebook locally, make sure you have created a virtual environment (using `conda` for example) and have the proper packages installed. We are working with `python=3.10` and `torch>=2`.\n",
    "\n",
    "Files to be included in submission:\n",
    "\n",
    "- `HW5.ipynb`\n",
    "- `model_config.yaml`\n",
    "- `train_config.yaml`\n",
    "- `state_dict.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DO NOT ADD ANY ADDITIONAL IMPORTS IN THE NOTEBOOK.\n",
    "\"\"\"\n",
    "import os\n",
    "from typing import Sequence, Dict, Union\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "try:\n",
    "    import torch_geometric as gtorch\n",
    "except ImportError:\n",
    "    os.system('pip install torch_geometric -qq')\n",
    "    os.system('pip install torch-scatter -qq')\n",
    "    import torch_geometric as gtorch\n",
    "\n",
    "import torch_geometric.data as gdata\n",
    "from torch_geometric import nn as gnn\n",
    "from torch_geometric.loader import DataLoader as gDataLoader\n",
    "\n",
    "from HW5_utils import Tracker, print_tensor_info # just in case you need it\n",
    "from HW5_utils import test_graph_convolution, save_yaml, load_yaml, zip_files, train\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    Device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    Device = 'mps'\n",
    "else:\n",
    "    Device = 'cpu'\n",
    "\n",
    "print(f'Device is {Device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Graph Convolutional Operator (30)\n",
    "\n",
    "Your first task is to implement the graph convolution operator that is calculated in the [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html) layer, but __only using `numpy`__. You can see the mathematical definition in the paper and in the online documentation. Basically, you are going to implement the following:\n",
    "\n",
    "$$ \n",
    "X' = D^{-1/2} A D^{-1/2} X \\Theta\n",
    "$$\n",
    "\n",
    "First you should get more familiar with how a graph is defined. In a general graph, edges have directions, and information flows from the source node to the target node. In our code, edges are defined by `edge_index`, which is of the shape `(2, num_edges)`. Each column corresponds to one edge and has two elements: the first (at index `0`) is the source node's index `j` and the second (at index `1`) is the target node's index `i`. This makes nodes `j` a neighbor of node `i`, or in mathematical notation $j\\in\\mathcal{N}(i)$. In the adjacency matrix, `A[i, j]` should be $e_{j, i}$ (the edge weight) if `j` is a neighbor of `i` and $0$ otherwise. You have to create $A$ from `edge_index` and `edge_weights` (without `for` loops).\n",
    "\n",
    "If `add_self_loops=True`, you have to modify $A$ so there is an edge with weight 1 connecting each node to itself.\n",
    "\n",
    "$\\hat{D}^{-1/2}$ is a diagonal matrix (zero on non-diagonal elements), with the $i$-th element on its diagonal being $d_i^{-1/2}$ where $d_i=\\sum_{j\\in\\mathcal{N}(i)} e_{j, i}$. You can calculate this matrix from the adjacency matrix $A$.\n",
    "\n",
    "**REMEMBER**: `for` loops make things slow. Therefore, there is a penalty of `-5` for each unnecessary `for` loop. An essential skill you have to learn is to _vectorize_ your operations and calculations, which basically means to avoid using `for` loops and instead make use of parallel computing provided by functions in libraries like `numpy` and `torch`. You can look back at recitation zero to see how you can index tensors or arrays with other tensors or arrays.\n",
    "\n",
    "You can test your function by comparing it to the output of the actual `GCNConv` layer from `gtorch`. The test function is provided to you, so you can try as much as you want until you get it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGRADED\n",
    "\n",
    "# Only numpy allowed\n",
    "def graph_convolution(\n",
    "        x: np.ndarray, # shape: (num_nodes, in_channels), dtype: np.float32\n",
    "        edge_index: np.ndarray, # shape: (2, num_edges), dtype: np.int64\n",
    "        edge_weights: np.ndarray, # shape: (num_edges,), dtype: np.float32\n",
    "        theta: np.ndarray, # shape: (in_channels, out_channels), dtype: np.float32\n",
    "        add_self_loops: bool = True,\n",
    "        ) -> np.ndarray: # shape: (num_nodes, out_channels), dtype: np.float32\n",
    "        \n",
    "    \n",
    "    num_nodes = x.shape[0]\n",
    "    \n",
    "    # Create adjacency matrix A\n",
    "    A = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
    "    A[edge_index[1], edge_index[0]] = edge_weights  # A[i, j] = e_{j, i}\n",
    "    \n",
    "    # Add self-loops\n",
    "    if add_self_loops:\n",
    "        A += np.eye(num_nodes, dtype=np.float32)\n",
    "    \n",
    "    # Compute degree matrix D\n",
    "    D = np.sum(A, axis=1)  # Sum over rows to get degree of each node\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(D + 1e-8))  # Avoid division by zero\n",
    "    \n",
    "    # Compute normalized adjacency matrix: D^(-1/2) A D^(-1/2)\n",
    "    A_norm = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    \n",
    "    # Perform convolution operation\n",
    "    x_prime = A_norm @ x @ theta\n",
    "    \n",
    "    return x_prime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test your code.\n",
    "\"\"\"\n",
    "test_graph_convolution(graph_convolution, num_tests=5, show_failed_edge_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement and train a GNN (70)\n",
    "Your second task in this assignment is to define and train a model to predict log solubility of molecules in water. You have to define a model and achieve a low enough loss by finding a good model and training it. The dataset class is provided to you. Use it to inspect the data and find out the information you need to define your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str,\n",
    "            ):\n",
    "        super().__init__()\n",
    "        np_data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "        self.samples = []\n",
    "        for i, (x, edge_index, edge_attr, y) in enumerate(np_data):\n",
    "            self.samples.append(\n",
    "                gdata.Data(\n",
    "                    x = torch.tensor(np.array(x), dtype=torch.float32),\n",
    "                    edge_index = torch.tensor(np.array(edge_index), dtype=torch.long),\n",
    "                    edge_attr = torch.tensor(np.array(edge_attr), dtype=torch.float32),\n",
    "                    y = torch.tensor(np.array(y).reshape(1, 1), dtype=torch.float32)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in dataset: 904\n",
      "Sample graph data: Data(x=[32, 37], edge_index=[2, 68], edge_attr=[68, 6], y=[1, 1])\n",
      "Batch data: DataBatch(x=[382, 37], edge_index=[2, 780], edge_attr=[780, 6], y=[32, 1], batch=[382], ptr=[33])\n",
      "Data(x=[32, 37], edge_index=[2, 68], edge_attr=[68, 6], y=[1, 1])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inspect the dataset. You can also create a gDataLoader to inspect the batched data.\n",
    "\"\"\"\n",
    "my_dataset = GraphDataset('data/train.npy')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(f\"Number of graphs in dataset: {len(my_dataset)}\")\n",
    "print(f\"Sample graph data: {my_dataset[0]}\")  # Print first sample\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "train_loader = gDataLoader(my_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Inspect a batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batch data: {batch}\")\n",
    "print(my_dataset[0])  # Inspect the first graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your Model (60)\n",
    "\n",
    "Implement a model to predict the log solubility of a molecule which is represented as a graph. This is a graph regression task, so you need one output per sample graph. Your model's forward method should process batched graphs. Define some [graph convolution layers](https://pytorch-geometric.readthedocs.io/en/2.5.1/modules/nn.html#convolutional-layers) for node-level processing and message passing, then use a global pooling function, and the rest is like normal fully connected networks. Don't forget nonlinear activation between layers.\n",
    "\n",
    "You should also use `edge_attr` from the input to pass in `edge_weight` for your `gnn` modules' forward pass. However, `edge_attr` represents each edge as a feature vector, but `edge_weight` needs a nonnegative scalar per edge. Therefore, you should define a learnable module for each layer to calculate the `edge_weight` from the `edge_attr`. You have to make sure the shape is right, since `edge_weight` should be of shape `(num_edges,)`. You should also use some activation function to restrict the range of your edge weights and make sure they are nonnegative values. What activation is appropriate here?\n",
    "\n",
    "Keep your code organized and clean, and remove debugging code and print statements after you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGRADED\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels, \n",
    "            hidden_channels, \n",
    "            out_channels\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = gnn.GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = gnn.GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            # Batched graph:\n",
    "            x: torch.FloatTensor, # shape: (num_nodes, in_channels)\n",
    "            edge_index: torch.LongTensor, # shape: (2, num_edges)\n",
    "            edge_attr: torch.FloatTensor, # shape: (num_edges, edge_channels)\n",
    "            batch: torch.LongTensor, # shape: (num_nodes,)\n",
    "            ) -> torch.FloatTensor: # shape: (batch_size, 1)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = gnn.global_mean_pool(x, batch)  # Aggregate node features\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, 1) # -1 just means it can be any parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and train a good model (10)\n",
    "The dataset is small, so the training should be relatively fast. Look for a good model and when you think you have found a good one, submit to Gradescope to see your test loss. Your score for this part is:\n",
    "\n",
    "$\\text{test MSE} \\leq 0.7$ : 15 points (5 bonus)\n",
    "\n",
    "$0.7 < \\text{test MSE} \\leq 0.9$ : 10 points\n",
    "\n",
    "$0.9 < \\text{test MSE} \\leq 1.1$ : 5 points\n",
    "\n",
    "$\\text{test MSE} > 1.1$ : 0 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 1/200 [00:03<10:25,  3.14s/epoch, Loss: 2.2960]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m my_dataset \u001b[38;5;241m=\u001b[39m GraphDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_config)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmy_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cmu_grad/deep_learning/HW5/HW5_utils.py:223\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, loss_fn, device, plot_freq, optimizer_name, optimizer_config, lr_scheduler_name, lr_scheduler_config, batch_size, n_epochs)\u001b[0m\n\u001b[1;32m    219\u001b[0m epoch_pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_pbar:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph_data_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m eval_epoch(\n\u001b[1;32m    232\u001b[0m         model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m    233\u001b[0m         graph_data_loader \u001b[38;5;241m=\u001b[39m train_loader,\n\u001b[1;32m    234\u001b[0m         loss_fn \u001b[38;5;241m=\u001b[39m loss_fn,\n\u001b[1;32m    235\u001b[0m         device \u001b[38;5;241m=\u001b[39m device,\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lr_scheduler_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReduceLROnPlateau\u001b[39m\u001b[38;5;124m'\u001b[39m: \n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cmu_grad/deep_learning/HW5/HW5_utils.py:173\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, graph_data_loader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m    171\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m    172\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 173\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:130\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    129\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/py3-10-ml-env-C8y3MhrL-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:379\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    376\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choose the configuration of your model and training\n",
    "\"\"\"\n",
    "\n",
    "model_config = dict(\n",
    "    in_channels = 37,  \n",
    "    hidden_channels = 1024,  \n",
    "    out_channels = 1,  \n",
    "    )\n",
    "\n",
    "train_config = dict(\n",
    "    optimizer_name = \"Adam\",\n",
    "    optimizer_config = dict(lr = 1e-3, weight_decay = 3e-4),\n",
    "    lr_scheduler_name = \"StepLR\",\n",
    "    lr_scheduler_config = dict(step_size = 40, gamma = 0.59),\n",
    "    batch_size = 8,\n",
    "    n_epochs = 200,\n",
    "    )\n",
    "\n",
    "# train_config = dict(\n",
    "#     optimizer_name = \"Adam\",\n",
    "#     optimizer_config = dict(lr = 1e-3, weight_decay = 3e-4),\n",
    "#     lr_scheduler_name = \"StepLR\",\n",
    "#     lr_scheduler_config = dict(step_size = 50, gamma = 0.63),\n",
    "#     batch_size = 16,\n",
    "#     n_epochs = 200,\n",
    "#     )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    my_dataset = GraphDataset('data/train.npy')\n",
    "    model = Model(**model_config)\n",
    "    train(\n",
    "        model = model,\n",
    "        train_dataset = my_dataset,\n",
    "        loss_fn = nn.MSELoss(),\n",
    "        device = Device,\n",
    "        plot_freq = 10,\n",
    "        **train_config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip submission files\n",
    "\n",
    "You can run the following cell to zip the generated files for submission.\n",
    "\n",
    "If you are on Colab, make sure to download and then upload a completed copy of the notebook to the working directory so the code can detect and include it in the zip file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_119777/1520653395.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load('state_dict.pt', map_location='cpu'))\n"
     ]
    }
   ],
   "source": [
    "save_yaml(model_config, 'model_config.yaml')\n",
    "save_yaml(train_config, 'train_config.yaml')\n",
    "torch.save(model.cpu().state_dict(), 'state_dict.pt')\n",
    "\n",
    "# Test if the model can be loaded successfully\n",
    "loaded_model = Model(**load_yaml('model_config.yaml')).cpu()\n",
    "loaded_model.load_state_dict(torch.load('state_dict.pt', map_location='cpu'))\n",
    "\n",
    "files_to_zip = ['HW5.ipynb', 'model_config.yaml', 'train_config.yaml', 'state_dict.pt']\n",
    "output_zip = 'HW5_submission.zip'\n",
    "zip_files(output_zip, *files_to_zip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-10-ml-env-C8y3MhrL-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
