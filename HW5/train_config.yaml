optimizer_name: Adam
optimizer_config: {lr: 0.001, weight_decay: 0.00025}
lr_scheduler_name: StepLR
lr_scheduler_config: {step_size: 40, gamma: 0.63}
batch_size: 8
n_epochs: 200
