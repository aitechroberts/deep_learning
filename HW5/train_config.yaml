optimizer_name: Adam
optimizer_config: {lr: 0.001, weight_decay: 0.00027}
lr_scheduler_name: StepLR
lr_scheduler_config: {step_size: 40, gamma: 0.56}
batch_size: 8
n_epochs: 200
