The difference between SVM and DL is that Neural Networks do representation and learning simultaneously

Universal Function Approximator

Minimizing empirical risk
- What is empirical risk?

w_2 = w_1 - partial derivatve of w_1 wrt Loss
- subtract the loss of the local derivative from the weight and subtracting because you are going down aka "descending"



## Heuristic Methods
F(x;w) = Neural Network Loss Curve and it can be crazily shaped making it hard for the gradient to descend

How to change a crazy surface of the loss curve that the gradient descends down?
1. Weight Regularization
2. Weight Initialization
3. Data Augmentation
4. Data Normalization
5. Drop Out

**Weight Initialization**





